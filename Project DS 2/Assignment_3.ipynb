{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3212dfe8",
   "metadata": {},
   "source": [
    "# prepare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c18713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from PIL import Image #Bildbearbeitungspacket (PIL = Pillow)\n",
    "import numpy as np\n",
    "import os # provides functions for creating and removing a directory (folder), fetching its contents, changing and identifying the current directory, etc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4414474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_traindata(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image in sorted(os.listdir(str(path))):\n",
    "        im = Image.open(str(path)+str(image))\n",
    "        im = im.resize((200,200)) #resize to get all images to the same dimension\n",
    "        images.append(np.array(im))\n",
    "        if image[4] == 'M':\n",
    "            labels.append(True)\n",
    "        else:\n",
    "            labels.append(False)\n",
    "                \n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e599234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in trainings and test images\n",
    "\n",
    "train_images, train_labels = read_traindata('fold1/train/400X/')\n",
    "\n",
    "test_images, test_labels = read_traindata('fold1/test/400X/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884f2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert train_images, train_labels, test_images and test_labels to a numpy array\n",
    "train_images = np.array(train_images) \n",
    "train_labels = np.array(train_labels) \n",
    "test_images = np.array(test_images)\n",
    "\n",
    "#reshape train_labels and test_lab\n",
    "train_labels = np.reshape(train_labels,(-1,1)) #-1 for unknown dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbc8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver train_labels to one-hot encoding\n",
    "#hierbei wird aus [False] [1. 0.] und aus [True] [0. 1.]\n",
    "\n",
    "enc = OneHotEncoder() #a new binary variable is added for each unique integer value\n",
    "train_lab = enc.fit_transform(train_labels).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5aa74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize images by dividing them with the maximum number of pixel\n",
    "# jetzt liegen die Werte zwischen 0 und 1\n",
    "\n",
    "train_im = train_images / 255.0\n",
    "test_im = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22f311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 2), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "buffer_size = len(train_im) \n",
    "print(buffer_size)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_im, train_lab)).shuffle(buffer_size).batch(32) #rain_ds has two tensors that are randomly sampled and batched. These tensors represent the training images and labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a9569",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704686fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class CNN_Model by using Model and modifying it\n",
    "# CNN_Model can identify patterns and is therefore usefull for Image analysis\n",
    "# we use a convolutional/faltendes Neural Network (CNN) with dense layers for class prediction\n",
    "# A convolutional layer has a number of filters that do convolutional operations. \n",
    "\n",
    "\n",
    "class CNN_Model(Model):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, padding='same', activation='relu') #2D convolution layer (e.g. spatial convolution over images). --> Filter der über das Bild bewegt wird\n",
    "        self.pool1 = MaxPool2D((2,2)) #Max pooling operation for 2D spatial data. --> nimmt größten Wert im Fenster 2x2 --> viertelt Anzahl an Werten\n",
    "        self.conv2 = Conv2D(64, 3, padding='same', activation='relu')\n",
    "        self.pool2 = MaxPool2D((2,2))\n",
    "        self.flatten = Flatten() #Flattens the input. Does not affect the batch size. --> \"bild wird langgezogen --> 1 dimensional\"\n",
    "        self.d1 = Dense(512, activation='relu') #normal NN layer, with relu as an activation function\n",
    "        self.dropout1 = Dropout(0.4) # Applies Dropout to the input.\n",
    "        self.d2 = Dense(128, activation='relu') \n",
    "        self.dropout2 = Dropout(0.4)\n",
    "        self.d3 = Dense(43, activation='relu')\n",
    "        self.d4 = Dense(2, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.d3(x)\n",
    "        x = self.d4(x)\n",
    "        return x\n",
    "    \n",
    "model_CNN = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c3074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object for our model\n",
    "#we use  Adam as our optimizer\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "#define our loss functions\n",
    "#We use categorical cross-entropy as our loss function \n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss') # mean value of all losses for each epoch\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy') #the accuracy measure of our model for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78addc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #this decorator converts the function into a graph.\n",
    "def train_step(images, labels):\n",
    "    'function to train our model and computes the loss and gradients'\n",
    "    with tf.GradientTape() as tape:\n",
    "        'tf.GradientTape() is a high-level API that is used to compute differentiations'\n",
    "        predictions = model_CNN(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model_CNN.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model_CNN.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62090308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: tf.Tensor(1.1916065, shape=(), dtype=float32)  Accuracy: tf.Tensor(66.09442, shape=(), dtype=float32)\n",
      "Epoch: 2  Loss: tf.Tensor(0.5641064, shape=(), dtype=float32)  Accuracy: tf.Tensor(72.36052, shape=(), dtype=float32)\n",
      "Epoch: 3  Loss: tf.Tensor(0.5259005, shape=(), dtype=float32)  Accuracy: tf.Tensor(71.75966, shape=(), dtype=float32)\n",
      "Epoch: 4  Loss: tf.Tensor(0.5248934, shape=(), dtype=float32)  Accuracy: tf.Tensor(76.30901, shape=(), dtype=float32)\n",
      "Epoch: 5  Loss: tf.Tensor(0.51930445, shape=(), dtype=float32)  Accuracy: tf.Tensor(72.96137, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build and train our model\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    model_CNN.save_weights('./content', save_format='tf')\n",
    "    \n",
    "    print('Epoch:',str(epoch+1),' Loss:',str(train_loss.result()),' Accuracy:', str(train_accuracy.result()*100))\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1755b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model_CNN(test_im),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f93ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816793893129771\n"
     ]
    }
   ],
   "source": [
    "correct = predictions == test_labels\n",
    "print(sum(correct)/len(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184efeff",
   "metadata": {},
   "source": [
    "# fully connected NN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa07556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected --> erst flatten, dann dense\n",
    "# we use a fully connected neural network\n",
    "#https://medium.com/swlh/fully-connected-vs-convolutional-neural-networks-813ca7bc6ee5\n",
    "#fully connected:\n",
    "# connect every neuron in one layer to every neuron in the other layer.\n",
    "\n",
    "class fully_c_Model(Model):\n",
    "    def __init__(self):\n",
    "        super(fully_c_Model, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.d0 = Dense(2330, activation='relu') #2048 = number of weights\n",
    "        self.d1 = Dense(1165, activation='relu')\n",
    "        self.d2 = Dense(582, activation='relu')\n",
    "        self.d3 = Dense(291, activation='relu')\n",
    "        self.d4 = Dense(146, activation='relu')\n",
    "        self.d5 = Dense(2, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.flatten(x) \n",
    "        x = self.d0(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.d5(x)\n",
    "        return x\n",
    "    \n",
    "model_fully_c = fully_c_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1266aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdefddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #this decorator converts the function into a graph.\n",
    "def train_step(images, labels):\n",
    "    'function to train our model and computes the loss and gradients'\n",
    "    with tf.GradientTape() as tape:\n",
    "        'tf.GradientTape() is a high-level API that is used to compute differentiations'\n",
    "        predictions = model_fully_c(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model_fully_c.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model_fully_c.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b1d8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: tf.Tensor(29.817862, shape=(), dtype=float32)  Accuracy: tf.Tensor(53.99142, shape=(), dtype=float32)\n",
      "Epoch: 2  Loss: tf.Tensor(2.5358858, shape=(), dtype=float32)  Accuracy: tf.Tensor(61.37339, shape=(), dtype=float32)\n",
      "Epoch: 3  Loss: tf.Tensor(0.6806833, shape=(), dtype=float32)  Accuracy: tf.Tensor(65.92275, shape=(), dtype=float32)\n",
      "Epoch: 4  Loss: tf.Tensor(0.5686251, shape=(), dtype=float32)  Accuracy: tf.Tensor(75.19313, shape=(), dtype=float32)\n",
      "Epoch: 5  Loss: tf.Tensor(0.50332826, shape=(), dtype=float32)  Accuracy: tf.Tensor(78.45493, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build and train our model\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    model_fully_c.save_weights('./content', save_format='tf')\n",
    "    \n",
    "    print('Epoch:',str(epoch+1),' Loss:',str(train_loss.result()),' Accuracy:', str(train_accuracy.result()*100))\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82e2a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model_fully_c(test_im),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a18501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213740458015267\n"
     ]
    }
   ],
   "source": [
    "correct = predictions == test_labels\n",
    "print(sum(correct)/len(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f993fc",
   "metadata": {},
   "source": [
    "# shallow NN model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f4b84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "lstm = tf.keras.layers.LSTM(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shallow_Model(Model):\n",
    "    def __init__(self):\n",
    "        super(shallow_Model, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(2000, activation='relu')\n",
    "        self.d2 = Dense(2, activation='softmax')\n",
    "       \n",
    "        \n",
    "    def call(self, x): \n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return x\n",
    "    \n",
    "model_shallow = shallow_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df9b29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42981ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #this decorator converts the function into a graph.\n",
    "def train_step(images, labels):\n",
    "    'function to train our model and computes the loss and gradients'\n",
    "    with tf.GradientTape() as tape:\n",
    "        'tf.GradientTape() is a high-level API that is used to compute differentiations'\n",
    "        predictions = model_shallow(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model_shallow.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model_shallow.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a511eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: tf.Tensor(45.85336, shape=(), dtype=float32)  Accuracy: tf.Tensor(64.67811, shape=(), dtype=float32)\n",
      "Epoch: 2  Loss: tf.Tensor(5.3578353, shape=(), dtype=float32)  Accuracy: tf.Tensor(68.8412, shape=(), dtype=float32)\n",
      "Epoch: 3  Loss: tf.Tensor(2.4574704, shape=(), dtype=float32)  Accuracy: tf.Tensor(69.87125, shape=(), dtype=float32)\n",
      "Epoch: 4  Loss: tf.Tensor(2.081162, shape=(), dtype=float32)  Accuracy: tf.Tensor(68.669525, shape=(), dtype=float32)\n",
      "Epoch: 5  Loss: tf.Tensor(2.101782, shape=(), dtype=float32)  Accuracy: tf.Tensor(68.06867, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build and train our model\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    model_shallow.save_weights('./content', save_format='tf')\n",
    "    \n",
    "    print('Epoch:',str(epoch+1),' Loss:',str(train_loss.result()),' Accuracy:', str(train_accuracy.result()*100))\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "650ba6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model_shallow(test_im),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e058a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572519083969466\n"
     ]
    }
   ],
   "source": [
    "correct = predictions == test_labels\n",
    "print(sum(correct)/len(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61810d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
